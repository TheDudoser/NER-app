from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from src.analysis.tfidf import lemma_analyzer_with_numbers
from src.analysis.phrase_extractor import PhraseExtractor
import nltk

nltk.download('punkt_tab')

text = """
Жила-была в одной деревне девочка красоты невиданной: мать любила её без памяти, а бабушка и того больше.

Сшила как-то раз бабушка любимой внучке шапочку красного цвета и так сильно она девочке понравилась, что и снимать не хотелось. Всюду ходила она в своей шапочке, потому и стали называть её Красной Шапочкой.

Раз испекла мама пирожки и говорит своей дочке:

— Сходи-ка ты навести бабушку, ей нездоровится. Да отнеси ей пирожки и горшочек масла. Смотри только в лесу не останавливайся и ни с кем не разговаривай.

Красная Шапочка была послушной девочкой, она сейчас же собралась и отправилась к бабушке, которая жила в другой деревне.

Идёт она по лесной тропинке и тут навстречу ей волк. Волк хотел было её съесть, да побоялся, потому что поблизости был слышен стук дровосеков. Вот он и спрашивает:

— Куда ты идёшь, Красная Шапочка?

Бедная девочка забыла, что опасно в лесу останавливаться и разговаривать с волками, и отвечает ему:

— Иду к бабушке; несу ей пирожки да горшочек масла.

— А далеко живёт твоя бабушка? — спрашивает волк.

— Очень далеко! — отвечает Красная Шапочка: — вон за той мельницей, что виднеется на опушке леса; а там будет первый дом как войдёшь в деревню.

— Знаешь, — говорит ей волк: — пойду-ка и я навещу твою бабушку. — Я пойду этой дорогой, а ты ступай по той: посмотрим, кто из нас быстрее дойдёт.

И волк бросился изо всех сил бежать по самой короткой дороге, а девочка побрела не спеша по самой длинной. По пути она собирала букеты и напевала песенки.

Прибежал волк первым к бабушкину дому. Постучался:

— Тук, тук.

— Кто там?

— Это я, внучка ваша, Красная Шапочка, — отвечал волк тоненьким голоском: — принесла вам пирожки да горшочек масла.

Бабушка лежала в постели, потому что ей немного нездоровилось, и крикнула оттуда:

— Дёрни за верёвочку, дверь сама и откроется.

Волк дёрнул за верёвочку, дверь открылась. Он бросился на старушку и разом проглотил её, потому что уже больше трёх дней ничего не кушал.

Потом он запер дверь, улегся в бабушкину постель и стал поджидать Красную Шапочку, которая через некоторое время добрела до бабушкиного домика и постучалась:

— Тук, тук.

— Кто там?

Услышав грубый голос, Красная Шапочка сперва было испугалась, но подумав, что видимо у бабушки голос осип из-за болезни, отвечала:

— Это я, внучка ваша, Красная Шапочка, принесла вам пирожки да горшочек масла.

Волк крикнул, как только мог тонким голосом:

— Дёрни за верёвочку, дверь сама и откроется.

Красная Шапочка дёрнула за верёвочку, дверь открылась. Когда девочка вошла, волк закутался хорошенько в одеяло, чтоб она его не узнала, и говорит:

— Положи куда-нибудь пирожок да горшочек масла, и иди приляг со мною, отдохни с дороги.

Красная Шапочка прилегла рядом и спрашивает:

— Бабушка, бабушка, а почему у тебя такие большие руки?

— Это, внучка, чтобы покрепче тебя обнимать.

— Бабушка, бабушка, а почему у тебя такие большие уши?

— Это, внучка, чтобы получше тебя слышать.

— Бабушка, бабушка, а почему у тебя такие большие глаза?

— Это, внучка, чтобы получше тебя видеть.

— Бабушка, бабушка, а почему у тебя такие большие зубы?

— А это, чтобы тебя съесть!

И с этими словами злой волк бросился на Красную Шапочку и проглотил её. Хорошо, что в ту пору в лесу работали дровосеки. Они услышали шум и вбежали в дом, где сразу кинулись к волку. Освободили Красную Шапочку и бабушку. Обе были целые и невредимые.

"""

# 1) Разметка терминов
pe = PhraseExtractor()
analysis = pe.analyze_text_with_stats(text)  # [4]
terms = [p['phrase'] for p in analysis['phrases']]
term_ids = [f"t{i}" for i in range(len(terms))]

sentences = nltk.sent_tokenize(text, language='russian')

# 2. Готовим два параллельных списка:
#    raw_sentences  - оригинальные предложения
#    lemma_sentences - предложения, лемматизированные и объединённые
lemma_sentences = []
for s in sentences:
    # леммы всех униграмм в предложении
    lemmas = lemma_analyzer_with_numbers(s, max_n=1)
    # строка лемм через пробел
    lemma_sentences.append(" ".join(lemmas))

# Лемматизируем термы так же, как при построении индекса
term_lemmas = []
for t in terms:
    # берем только биграммы+униграммы
    grams = lemma_analyzer_with_numbers(t, max_n=2)
    # ищем ровно тот n-грамм, который соответствует всей фразе
    # (на первом месте вернётся «горшочек масло» и т.д.)
    term_lemmas.append(grams[0])

# 4. Строим TF-IDF по леммам терминов
vectorizer = TfidfVectorizer(
    analyzer=lambda txt: txt.split()  # уже леммы
)
tfidf_matrix = vectorizer.fit_transform(term_lemmas)


def search(query: str, top_n: int = 3):
    # 4.1. лемматизируем запрос так же, как термы
    q_gram = lemma_analyzer_with_numbers(query, max_n=2)[0]
    q_vec = vectorizer.transform([q_gram])
    sims = cosine_similarity(q_vec, tfidf_matrix).flatten()
    top = sims.argsort()[::-1][:top_n]

    results = []
    for idx in top:
        score = float(sims[idx])
        phrase = terms[idx]
        lemma_phrase = term_lemmas[idx]
        # 4.2. ищем все предложения, где входит лемматизированная фраза
        hits = []
        for raw, lemma_s in zip(sentences, lemma_sentences):
            if lemma_phrase in lemma_s.split():
                hits.append(raw)
        results.append({
            "phrase": phrase,
            "score": score,
            "sentences": hits
        })
    return results


# 5. Демонстрация
for q in ["горшочек масла", "бабушка"]:
    print(f"Query: «{q}»")
    for r in search(q):
        print(f"  Термин: {r['phrase']}, score={r['score']:.3f}")
        for s in r["sentences"]:
            print(f"    ▶ {s}")
    print()
